{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.\n",
    "* Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n",
    "* Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n",
    "* Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred).\n",
    "* Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score.\n",
    "* Могла ли модель переобучиться? Почему?\n",
    "* Создайте функции eval_model_l1 и eval_model_l2 с применением L1 и L2 регуляризаций соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    eps = 1e-10\n",
    "    y_pred[y_pred == 0] = 0 + eps\n",
    "    y_pred[y_pred == 1] = 1 - eps\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y1 = np.array([1, 0])\n",
    "# y_pred1 = np.array([0.001, 1])\n",
    "# calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, max_iter, alpha):\n",
    "    W = np.zeros(2)\n",
    "    n = X.shape[1]\n",
    "    eps = 1e-8\n",
    "    weight_dist = np.inf\n",
    "    i = 0\n",
    "    while weight_dist > eps and i < max_iter:\n",
    "        \n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W_new = W - alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "        \n",
    "        weight_dist = np.linalg.norm(W_new - W, ord = 2)\n",
    "        i += 1\n",
    "        W = W_new\n",
    "    return W, i, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params(X, y, *params):\n",
    "    a = []\n",
    "    for vals in itertools.product(iters, etas):\n",
    "        W, i, err = eval_model(X, y, *vals) # для логистической регрессии eval_model!\n",
    "        a.append([*vals, W, i, err])\n",
    "\n",
    "    ind = [params[-1] for params in a].index(min([params[-1] for params in a]))\n",
    "    best_err = a[ind][4]\n",
    "    best_eta = a[ind][1]\n",
    "    if a[ind][0] > a[ind][3]: #алгоритм сошелся раньше, чем достигли max_iter\n",
    "        best_iter = a[ind][3]\n",
    "    else: #алгоритм так и не сошелся при данных eta, max_iters\n",
    "        best_iter = a[ind][0] \n",
    "        print('алгоритм не сошелся')\n",
    "\n",
    "    return best_iter, best_err, best_eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(W, X):\n",
    "    y_pred_proba = sigmoid(W.T.dot(X))\n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(W, X, threshold = 0.5):\n",
    "\n",
    "    y_pred = calc_pred_proba(W, X)\n",
    "    y_pred[y_pred >= threshold] = 1\n",
    "    y_pred[y_pred < threshold] = 0\n",
    "    return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y, y_pred):\n",
    "    TP = ((y_pred == 1) & (y == 1)).sum()\n",
    "    FP = ((y_pred == 1) & (y == 0)).sum()\n",
    "    FN = ((y_pred == 0) & (y == 1)).sum()\n",
    "    TN = ((y_pred == 0) & (y == 0)).sum()\n",
    "    \n",
    "    return np.array([[TP, FP], [FN, TN]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(y, y_pred):\n",
    "    TP = ((y_pred == 1) & (y == 1)).sum()\n",
    "    FP = ((y_pred == 1) & (y == 0)).sum()\n",
    "    FN = ((y_pred == 0) & (y == 1)).sum()\n",
    "    TN = ((y_pred == 1) & (y == 0)).sum()\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1_score = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return precision, recall, F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерация данных\n",
    "# разница между метриками начинает появляться только после увеличения параметра генерации flip_y до 0.10, \n",
    "# на менее шумных данных нет разницы между трейном и тестом, регуляризация тоже ничего не меняет\n",
    "classes = datasets.make_classification(n_samples=100, \n",
    "                                       n_features=2, \n",
    "                                       n_informative=2,\n",
    "                                       n_redundant=0, \n",
    "                                       n_classes=2, \n",
    "                                       flip_y = 0.10, #шум\n",
    "                                       weights = [0.833, 0.167], #соотношение классов\n",
    "                                       random_state=1)\n",
    "X, y = classes[0].T, classes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наборы параметров\n",
    "etas = np.array([1e-2, 1e-4, 1e-6])\n",
    "iters = np.array([1000, 10000, 100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### обучаем модель на всем датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36742, 0.17105028128073477, 0.01)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_iter, best_err, best_eta = best_params(X, y, etas, iters)\n",
    "best_iter, best_err, best_eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.11943017,  3.36114494]), 0.17105028128073477)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, i, err = eval_model(X, y, best_iter, best_eta)\n",
    "W, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = calc_pred_proba(W, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = calc_pred(W, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(zip(y_pred_probs, y_pred, y))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### считаем метрики на всем датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.mean(y_pred == y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  1],\n",
       "       [ 4, 80]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y, y_pred)\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9375, 0.7894736842105263, 0.8571428571428572)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, F1_score = classification_report(y, y_pred)\n",
    "precision, recall, F1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### делим выборку на обучающую и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перемешивание датасета\n",
    "np.random.seed(12)\n",
    "shuffle_index = np.random.permutation(classes[0].shape[0])\n",
    "X_shuffled, y_shuffled = classes[0][shuffle_index], classes[1][shuffle_index]\n",
    "\n",
    "# разбивка на обучающую и тестовую выборки\n",
    "train_proportion = 0.7\n",
    "train_test_cut = int(len(classes[0]) * train_proportion)\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    X_shuffled[:train_test_cut], \\\n",
    "    X_shuffled[train_test_cut:], \\\n",
    "    y_shuffled[:train_test_cut], \\\n",
    "    y_shuffled[train_test_cut:]\n",
    "    \n",
    "X_train = X_train.T\n",
    "X_test = X_test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### обучаем на X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "алгоритм не сошелся\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100000, 0.0716071421399939, 0.01)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_iter_train, best_err_train, best_eta_train = best_params(X_train, y_train, etas, iters)\n",
    "best_iter_train, best_err_train, best_eta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.36426709, 5.00824682]), 100000, 0.0716071421399939)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_, i_, err_ = eval_model(X_train, y_train, best_iter_train, best_eta_train)\n",
    "W_, i_, err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs_train = calc_pred_proba(W_, X_train)\n",
    "y_pred_train = calc_pred(W_, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0],\n",
       "       [ 1, 59]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9090909090909091, 0.9523809523809523)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### проверяем на X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs_test = calc_pred_proba(W_, X_test)\n",
    "y_pred_test = calc_pred(W_, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  1],\n",
       "       [ 2, 21]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8571428571428571, 0.75, 0.7999999999999999)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При таком уровне шума на тесте результаты уже хуже, чем на трейне"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1, L2 регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_l1(X, y, max_iter, alpha, lambda_ = 1e-8):\n",
    "    W = np.zeros(2)\n",
    "    n = X.shape[1]\n",
    "    eps = 1e-8\n",
    "    weight_dist = np.inf\n",
    "    i = 0\n",
    "    while weight_dist > eps and i < max_iter:\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W_new = W - alpha * (1/n * np.dot((y_pred - y), X.T) + lambda_* np.sign(W))\n",
    "        \n",
    "        weight_dist = np.linalg.norm(W_new - W, ord = 2)\n",
    "        i += 1\n",
    "        W = W_new\n",
    "    return W, i, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_l2(X, y, max_iter, alpha, lambda_ = 1e-8):\n",
    "    W = np.zeros(2)\n",
    "    n = X.shape[1]\n",
    "    eps = 1e-8\n",
    "    weight_dist = np.inf\n",
    "    i = 0\n",
    "    while weight_dist > eps and i < max_iter:\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W_new = W - alpha * (1/n * np.dot((y_pred - y), X.T) + 2 * lambda_* W)\n",
    "        \n",
    "        weight_dist = np.linalg.norm(W_new - W, ord = 2)\n",
    "        i += 1\n",
    "        W = W_new\n",
    "    return W, i, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.array([1e-4,1e-6, 1e-8, 1e-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1e-10, 0.07160714214026109, 100000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = []\n",
    "for l in lambdas:\n",
    "    W, i, err = eval_model_l1(X_train, y_train, best_iter_train, best_eta_train, l)\n",
    "    l1.append([l, W, i, err])\n",
    "\n",
    "ind = [params[-1] for params in l1].index(min([params[-1] for params in l1]))\n",
    "best_lambda_train = l1[ind][0]\n",
    "best_err_train = l1[ind][-1]\n",
    "best_i = l1[ind][2]\n",
    "best_lambda_train, best_err_train, best_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1e-10, 0.07160714214234898, 100000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = []\n",
    "for l in lambdas:\n",
    "    W, i, err = eval_model_l2(X_train, y_train, best_iter_train, best_eta_train, l)\n",
    "    l2.append([l, W, i, err])\n",
    "\n",
    "ind = [params[-1] for params in l2].index(min([params[-1] for params in l2]))\n",
    "best_err_train = l2[ind][-1]\n",
    "best_i = l2[ind][2]\n",
    "best_lambda_train, best_err_train, best_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "разницы между моделями без регуляризации, L1 b L2 в данном случае практически никакой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 X_train vs X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.36426706, 5.00824666]), 0.07160714214234898)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_l2, i_l2, err_l2 = eval_model_l2(X_train, y_train, best_iter_train, best_eta_train, best_lambda_train)\n",
    "W_l2, err_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs_train_l2 = calc_pred_proba(W_l2, X_train)\n",
    "y_pred_train_l2 = calc_pred(W_l2, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0],\n",
       "       [ 1, 59]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred_train_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9090909090909091, 0.9523809523809523)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_train, y_pred_train_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs_test_l2 = calc_pred_proba(W_l2, X_test)\n",
    "y_pred_test_l2 = calc_pred(W_l2, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  1],\n",
       "       [ 2, 21]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_test_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8571428571428571, 0.75, 0.7999999999999999)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, y_pred_test_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили практически те же результаты, что и на модели без регуляризации, за исключением ошибки - различается в 10м знаке после запятой (best_lambda = 1e-10, а веса получаются небольшими)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
